"""
Week 05: ç¼–ç æµ‹è¯•

æµ‹è¯• UTF-8 ç¼–ç ã€ä¸­æ–‡æ”¯æŒã€ä¸åŒç¼–ç ä¹‹é—´çš„å·®å¼‚
"""

import pytest
from pathlib import Path


class TestUTF8Encoding:
    """æµ‹è¯• UTF-8 ç¼–ç è¯»å†™"""

    def test_write_read_chinese_with_utf8(self, tmp_path):
        """æµ‹è¯•ç”¨ UTF-8 è¯»å†™ä¸­æ–‡"""
        file = tmp_path / "chinese.txt"
        chinese_content = "ä½ å¥½ï¼Œä¸–ç•Œï¼\nè¿™æ˜¯ä¸­æ–‡æµ‹è¯•ã€‚\n"

        # å†™å…¥æ—¶æŒ‡å®š UTF-8
        with open(file, "w", encoding="utf-8") as f:
            f.write(chinese_content)

        # è¯»å–æ—¶ä¹Ÿç”¨ UTF-8
        with open(file, "r", encoding="utf-8") as f:
            result = f.read()

        assert result == chinese_content
        assert "ä½ å¥½" in result
        assert "ä¸­æ–‡æµ‹è¯•" in result

    def test_write_read_mixed_languages(self, tmp_path):
        """æµ‹è¯•è¯»å†™æ··åˆè¯­è¨€æ–‡æœ¬"""
        file = tmp_path / "mixed.txt"
        mixed = "English, ä¸­æ–‡, æ—¥æœ¬èª, í•œêµ­\n"

        file.write_text(mixed, encoding="utf-8")
        content = file.read_text(encoding="utf-8")

        assert content == mixed
        assert "English" in content
        assert "ä¸­æ–‡" in content
        assert "æ—¥æœ¬èª" in content

    def test_pathlib_write_read_chinese(self, tmp_path):
        """æµ‹è¯• pathlib çš„ UTF-8 ä¸­æ–‡è¯»å†™"""
        file = tmp_path / "chinese.txt"
        text = "ä»Šå¤©å­¦ä¹ äº†æ–‡ä»¶ç¼–ç \nUTF-8 çœŸçš„å¾ˆæ–¹ä¾¿\n"

        file.write_text(text, encoding="utf-8")
        content = file.read_text(encoding="utf-8")

        assert content == text
        assert "ç¼–ç " in content

    def test_chinese_in_dict_format(self, tmp_path):
        """æµ‹è¯•ä¸­æ–‡åœ¨å­—å…¸æ ¼å¼çš„æ–‡æœ¬æ–‡ä»¶ä¸­"""
        file = tmp_path / "learning_log.txt"

        # å†™å…¥ç±»ä¼¼ PyHelper çš„å­¦ä¹ è®°å½•æ ¼å¼
        log = {
            "02-09": "å­¦ä¼šäº†åˆ—è¡¨å’Œå­—å…¸çš„åŸºæœ¬ç”¨æ³•",
            "02-10": "å†™äº†ä¸€ä¸ªæˆç»©å•é¡¹ç›®",
            "02-11": "ææ‡‚äº† UTF-8 ç¼–ç "
        }

        with open(file, "w", encoding="utf-8") as f:
            for date, content in log.items():
                f.write(f"{date}: {content}\n")

        # è¯»å–å¹¶éªŒè¯
        content = file.read_text(encoding="utf-8")
        assert "åˆ—è¡¨å’Œå­—å…¸" in content
        assert "æˆç»©å•é¡¹ç›®" in content
        assert "UTF-8" in content

    def test_unicode_emojis(self, tmp_path):
        """æµ‹è¯• Unicode emoji å­—ç¬¦çš„è¯»å†™"""
        file = tmp_path / "emoji.txt"
        emoji_text = "ä»Šå¤©å¾ˆå¼€å¿ƒ ğŸ˜Š\nåº†ç¥ä¸€ä¸‹ ğŸ‰\nå­¦ä¹ ç¼–ç¨‹ ğŸ’»\n"

        file.write_text(emoji_text, encoding="utf-8")
        content = file.read_text(encoding="utf-8")

        assert content == emoji_text
        assert "ğŸ˜Š" in content
        assert "ğŸ‰" in content


class TestEncodingBasics:
    """æµ‹è¯•ç¼–ç çš„åŸºæœ¬æ¦‚å¿µ"""

    def test_encode_string_to_bytes(self):
        """æµ‹è¯•å°†å­—ç¬¦ä¸²ç¼–ç ä¸ºå­—èŠ‚"""
        text = "ä¸­æ–‡"
        utf8_bytes = text.encode("utf-8")

        assert isinstance(utf8_bytes, bytes)
        assert len(utf8_bytes) == 6  # æ¯ä¸ªä¸­æ–‡å­—ç¬¦åœ¨ UTF-8 ä¸­å  3 å­—èŠ‚

    def test_decode_bytes_to_string(self):
        """æµ‹è¯•å°†å­—èŠ‚è§£ç ä¸ºå­—ç¬¦ä¸²"""
        text = "ä¸­æ–‡"
        utf8_bytes = text.encode("utf-8")

        decoded = utf8_bytes.decode("utf-8")
        assert decoded == text

    def test_different_encodings_produce_different_bytes(self):
        """æµ‹è¯•ä¸åŒç¼–ç äº§ç”Ÿä¸åŒçš„å­—èŠ‚åºåˆ—"""
        text = "ä¸­æ–‡"

        utf8_bytes = text.encode("utf-8")
        gbk_bytes = text.encode("gbk")

        # UTF-8 å’Œ GBK çš„å­—èŠ‚è¡¨ç¤ºä¸åŒ
        assert utf8_bytes != gbk_bytes

        # ä½†éƒ½èƒ½æ­£ç¡®è§£ç å›åŸæ–‡æœ¬
        assert utf8_bytes.decode("utf-8") == text
        assert gbk_bytes.decode("gbk") == text

    def test_wrong_encoding_decoding_fails(self):
        """æµ‹è¯•é”™è¯¯çš„ç¼–ç è§£ç ä¼šå¤±è´¥"""
        text = "ä¸­æ–‡"
        utf8_bytes = text.encode("utf-8")

        # ç”¨ GBK è§£ç  UTF-8 ç¼–ç çš„å­—èŠ‚ä¼šæŠ¥é”™æˆ–ä¹±ç 
        with pytest.raises(UnicodeDecodeError):
            utf8_bytes.decode("gbk")


class TestEncodingInFileOperations:
    """æµ‹è¯•æ–‡ä»¶æ“ä½œä¸­çš„ç¼–ç å¤„ç†"""

    def test_write_utf8_read_utf8(self, tmp_path):
        """æµ‹è¯• UTF-8 å†™å…¥å’Œè¯»å–åŒ¹é…"""
        file = tmp_path / "test.txt"
        content = "è¿™æ˜¯ä¸­æ–‡å†…å®¹"

        with open(file, "w", encoding="utf-8") as f:
            f.write(content)

        with open(file, "r", encoding="utf-8") as f:
            result = f.read()

        assert result == content

    def test_write_utf8_read_wrong_encoding(self, tmp_path):
        """æµ‹è¯•ç”¨é”™è¯¯çš„ç¼–ç è¯»å– UTF-8 æ–‡ä»¶"""
        file = tmp_path / "test.txt"
        # æŸäº›ä¸­æ–‡å­—ç¬¦åœ¨ UTF-8 ç¼–ç åæ— æ³•ç”¨ GBK æ­£ç¡®è§£ç 
        content = "ç‰¹æ®Šå­—ç¬¦ï¼šğŸ‰"

        with open(file, "w", encoding="utf-8") as f:
            f.write(content)

        # ç”¨ GBK è¯»å– UTF-8 ç¼–ç çš„æ–‡ä»¶ä¼šæŠ¥é”™
        with pytest.raises(UnicodeDecodeError):
            with open(file, "r", encoding="gbk") as f:
                f.read()

    def test_encoding_parameter_required_for_chinese(self, tmp_path):
        """æµ‹è¯•ä¸­æ–‡å¿…é¡»æŒ‡å®šæ­£ç¡®çš„ç¼–ç """
        file = tmp_path / "chinese.txt"
        content = "ä¸­æ–‡æµ‹è¯•"

        # ä¸æŒ‡å®š encodingï¼Œåœ¨æŸäº›ç³»ç»Ÿä¸Šå¯èƒ½ä½¿ç”¨é»˜è®¤ç¼–ç ï¼ˆä¸å®‰å…¨ï¼‰
        # ä½†é€šå¸¸ç°ä»£ Python é»˜è®¤ä¼šç”¨ UTF-8
        with open(file, "w", encoding="utf-8") as f:
            f.write(content)

        # è¯»å–æ—¶ä¹Ÿå¿…é¡»æŒ‡å®š encoding
        result = file.read_text(encoding="utf-8")
        assert result == content


class TestSpecialCharacters:
    """æµ‹è¯•ç‰¹æ®Šå­—ç¬¦çš„ç¼–ç å¤„ç†"""

    def test_newline_characters(self, tmp_path):
        """æµ‹è¯•æ¢è¡Œç¬¦çš„å¤„ç†"""
        file = tmp_path / "newlines.txt"
        # ä½¿ç”¨ç®€å•çš„æ¢è¡Œç¬¦ï¼Œé¿å…å¹³å°å·®å¼‚
        content = "Line 1\nLine 2\nLine 3\n"

        file.write_text(content, encoding="utf-8")
        result = file.read_text(encoding="utf-8")

        assert result == content
        assert "\n" in result

    def test_tabs_and_spaces(self, tmp_path):
        """æµ‹è¯•åˆ¶è¡¨ç¬¦å’Œç©ºæ ¼"""
        file = tmp_path / "tabs.txt"
        content = "Column1\tColumn2\tColumn3\n"

        file.write_text(content, encoding="utf-8")
        result = file.read_text(encoding="utf-8")

        assert result == content
        assert "\t" in result

    def test_quotes_and_backslashes(self, tmp_path):
        """æµ‹è¯•å¼•å·å’Œåæ–œæ """
        file = tmp_path / "quotes.txt"
        content = 'ä»–è¯´ï¼š"è¿™æ˜¯\'æµ‹è¯•\'å­—ç¬¦ä¸²"\nè·¯å¾„ï¼šC:\\Users\\Test\n'

        file.write_text(content, encoding="utf-8")
        result = file.read_text(encoding="utf-8")

        assert result == content

    def test_punctuation_marks(self, tmp_path):
        """æµ‹è¯•å„ç§æ ‡ç‚¹ç¬¦å·"""
        file = tmp_path / "punctuation.txt"
        content = "å…¨è§’æ ‡ç‚¹ï¼šï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šã€Œã€\nåŠè§’æ ‡ç‚¹:,.!?;:'\"\n"

        file.write_text(content, encoding="utf-8")
        result = file.read_text(encoding="utf-8")

        assert result == content


class TestEncodingEdgeCases:
    """æµ‹è¯•ç¼–ç çš„è¾¹ç•Œæƒ…å†µ"""

    def test_empty_string_encoding(self):
        """æµ‹è¯•ç©ºå­—ç¬¦ä¸²çš„ç¼–ç """
        text = ""
        utf8_bytes = text.encode("utf-8")

        assert utf8_bytes == b""
        assert len(utf8_bytes) == 0

    def test_very_long_chinese_text(self, tmp_path):
        """æµ‹è¯•å¾ˆé•¿çš„ä¸­æ–‡æ–‡æœ¬"""
        file = tmp_path / "long.txt"
        long_text = "è¿™æ˜¯ä¸€æ®µå¾ˆé•¿çš„ä¸­æ–‡æ–‡æœ¬ã€‚" * 1000

        file.write_text(long_text, encoding="utf-8")
        result = file.read_text(encoding="utf-8")

        assert result == long_text
        assert len(result) > 0

    def test_mixed_ascii_and_chinese(self, tmp_path):
        """æµ‹è¯• ASCII å’Œä¸­æ–‡æ··åˆ"""
        file = tmp_path / "mixed.txt"
        mixed = "Hello ä½ å¥½ World ä¸–ç•Œ Test æµ‹è¯•\n"

        file.write_text(mixed, encoding="utf-8")
        result = file.read_text(encoding="utf-8")

        assert result == mixed

    def test_unicode_escape_sequences(self, tmp_path):
        """æµ‹è¯• Unicode è½¬ä¹‰åºåˆ—"""
        file = tmp_path / "unicode.txt"

        # ç›´æ¥å†™å…¥ Unicode å­—ç¬¦
        text = "\u4e2d\u6587"  # "ä¸­æ–‡"
        file.write_text(text, encoding="utf-8")

        result = file.read_text(encoding="utf-8")
        assert result == "ä¸­æ–‡"

    def test_bom_byte_order_mark(self, tmp_path):
        """æµ‹è¯•å¸¦ BOM çš„ UTF-8"""
        file = tmp_path / "with_bom.txt"

        # UTF-8 with BOM (utf-8-sig)
        content = "ä¸­æ–‡å†…å®¹"
        with open(file, "w", encoding="utf-8-sig") as f:
            f.write(content)

        # ç”¨ utf-8-sig è¯»å–ä¼šè‡ªåŠ¨å¤„ç† BOM
        with open(file, "r", encoding="utf-8-sig") as f:
            result = f.read()

        assert result == content

    def test_rare_chinese_characters(self, tmp_path):
        """æµ‹è¯•ç”Ÿåƒ»ä¸­æ–‡å­—ç¬¦"""
        file = tmp_path / "rare.txt"
        rare_chars = "é¾˜éé½‰çˆ¨\n"  # ä¸€äº›ç”Ÿåƒ»å­—

        file.write_text(rare_chars, encoding="utf-8")
        result = file.read_text(encoding="utf-8")

        assert result == rare_chars


class TestPracticalEncodingScenarios:
    """æµ‹è¯•å®é™…ç¼–ç åº”ç”¨åœºæ™¯"""

    def test_diary_with_chinese(self, tmp_path):
        """æµ‹è¯•ä¸­æ–‡æ—¥è®°çš„å­˜å‚¨å’Œè¯»å–"""
        file = tmp_path / "diary.txt"

        entries = [
            "2026-02-09: ä»Šå¤©å­¦ä¼šäº†æ–‡ä»¶æ“ä½œï¼Œwith è¯­å¥å¾ˆæ–¹ä¾¿",
            "2026-02-10: ææ‡‚äº† UTF-8 ç¼–ç ï¼Œä¸ä¼šå†æœ‰ä¹±ç é—®é¢˜",
            "2026-02-11: è¿½åŠ æ¨¡å¼è®©æ—¥è®°æœ¬èƒ½æŒç»­è®°å½•"
        ]

        # å†™å…¥æ—¥è®°
        with open(file, "w", encoding="utf-8") as f:
            for entry in entries:
                f.write(entry + "\n")

        # è¯»å–æ—¥è®°
        with open(file, "r", encoding="utf-8") as f:
            lines = [line.strip() for line in f if line.strip()]

        assert len(lines) == 3
        assert "æ–‡ä»¶æ“ä½œ" in lines[0]
        assert "UTF-8" in lines[1]
        assert "è¿½åŠ æ¨¡å¼" in lines[2]

    def test_learning_log_with_dates(self, tmp_path):
        """æµ‹è¯•å¸¦æ—¥æœŸçš„å­¦ä¹ è®°å½•"""
        file = tmp_path / "learning.txt"

        data = {
            "02-09": "å­¦ä¼šäº†åˆ—è¡¨å’Œå­—å…¸çš„åŸºæœ¬ç”¨æ³•",
            "02-10": "å†™äº†æˆç»©å•é¡¹ç›®",
            "02-11": "å­¦ä¹ äº† pathlib å¤„ç†æ–‡ä»¶è·¯å¾„"
        }

        # å†™å…¥
        with open(file, "w", encoding="utf-8") as f:
            for date, content in data.items():
                f.write(f"{date}: {content}\n")

        # è¯»å–å¹¶è§£æ
        result = {}
        with open(file, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    parts = line.split(": ", 1)
                    if len(parts) == 2:
                        result[parts[0]] = parts[1]

        assert result == data

    def test_search_chinese_content(self, tmp_path):
        """æµ‹è¯•æœç´¢ä¸­æ–‡å†…å®¹"""
        file = tmp_path / "search_test.txt"

        content = """ç¬¬ä¸€è¡Œï¼šPython ç¼–ç¨‹
ç¬¬äºŒè¡Œï¼šæ–‡ä»¶æ“ä½œ
ç¬¬ä¸‰è¡Œï¼šå­—å…¸å’Œåˆ—è¡¨
ç¬¬å››è¡Œï¼šç¼–ç é—®é¢˜"""

        file.write_text(content, encoding="utf-8")

        # æœç´¢åŒ…å«"æ–‡ä»¶"çš„è¡Œ
        lines = file.read_text(encoding="utf-8").split("\n")
        matching = [line for line in lines if "æ–‡ä»¶" in line]

        assert len(matching) == 1
        assert "æ–‡ä»¶æ“ä½œ" in matching[0]
