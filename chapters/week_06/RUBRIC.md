# Week 06 评分标准：用测试守护代码质量

## 评分维度

| 维度 | 权重 | 优秀 (90-100) | 良好 (75-89) | 合格 (60-74) | 不合格 (<60) |
|------|------|--------------|-------------|-------------|-------------|
| **功能完成度** | 30% | 所有基础功能完成，含进阶作业（覆盖率 90%+）；CampusFlow 团队作业完整 | 基础功能完成，部分进阶功能（覆盖率 80%+）；CampusFlow 测试基本完整 | 仅完成基础功能，覆盖率达标但无进阶；CampusFlow 测试有遗漏 | 基础功能不完整，或测试无法运行 |
| **测试质量** | 30% | 覆盖率高（90%+），断言精准，测试命名清晰，边界情况考虑全面；能识别并补充 AI 遗漏的测试场景 | 覆盖率达标（80%+），主要路径覆盖，断言正确；能发现 AI 生成代码的明显问题 | 有测试但覆盖不足（<80%），或断言较弱；AI 审查流于表面 | 测试缺失或存在错误断言；未完成 AI 审查练习 |
| **代码规范** | 20% | 完全符合 Java 编码规范，测试结构清晰，@BeforeEach 使用恰当，无重复代码 | 基本符合规范，测试结构合理，少量重复代码 | 部分规范问题，如测试命名不清晰，或重复代码较多 | 严重规范问题，如测试无法维护，或大量复制粘贴 |
| **AI 协作能力** | 20% | AI 审查深入，发现关键问题（如边界遗漏、弱断言）；能写出让 AI 测试通过的"错误实现"；反思深刻 | 完成 AI 审查流程，发现 3 个以上问题；修复后的代码质量良好 | 简单使用 AI，审查不够深入；仅发现表面问题 | 未使用 AI 或误用（直接提交 AI 输出无审查） |

---

## 详细评分项

### 1. 功能完成度（30%）

**基础作业检查点**：
- [ ] `LibraryTrackerTest.java` 存在且可编译
- [ ] 使用了 `@BeforeEach` 初始化测试数据
- [ ] 测试了所有 Repository 方法（addBook, findBook, listAllBooks, hasBook, removeBook, borrowBook, returnBook, getBorrowRecordsByUser, getAllBorrowRecords）
- [ ] 使用了 `assertThrows` 测试至少 3 个异常场景
- [ ] 使用了 `@ParameterizedTest` 至少 1 处

**进阶作业检查点**（选做加分）：
- [ ] `pom.xml` 配置了 JaCoCo 插件
- [ ] 覆盖率报告截图显示整体覆盖率 >= 90%
- [ ] 补充了边界情况测试（空列表、重复添加等）

**CampusFlow 团队作业检查点**：
- [ ] 为 Repository 层编写了单元测试
- [ ] 核心方法（save/findById/findAll/delete）有测试覆盖
- [ ] 覆盖率 >= 80%
- [ ] 提交了分工与挑战说明

**评分细则**：
- 90-100：所有检查点通过，含进阶作业
- 75-89：基础作业完整，覆盖率 80%+，无进阶
- 60-74：基础作业有 1-2 个检查点未通过
- <60：多个检查点未通过，或测试无法运行

---

### 2. 测试质量（30%）

**断言质量**：
- 优秀：使用精准的断言（如 `assertEquals(expected, actual)` 而非仅 `assertNotNull`）
- 良好：断言正确，能验证预期行为
- 合格：断言基本正确，但有冗余或不够精准
- 不合格：断言错误，或测试通过但不验证实际行为

**边界情况覆盖**：
- 优秀：考虑了 null 输入、空字符串、空列表、重复数据等边界情况
- 良好：考虑了主要边界情况
- 合格：考虑了部分边界情况
- 不合格：仅测试了"happy path"

**测试命名**：
- 优秀：使用描述性命名（如 `shouldThrowExceptionWhenBorrowingWithNullIsbn`）
- 良好：命名基本清晰
- 合格：命名不够规范，但能看出测试目的
- 不合格：命名随意（如 `test1`、`test2`）

**AI 审查质量**（如完成 AI 协作练习）：
- 优秀：发现 3 个以上实质性问题（边界遗漏、弱断言、重复代码等）
- 良好：发现 3 个问题
- 合格：发现 1-2 个问题
- 不合格：未发现明显问题，或未完成审查

---

### 3. 代码规范（20%）

**测试结构**：
- 优秀：使用 `@BeforeEach` 消除所有重复初始化；测试方法独立，无相互依赖
- 良好：使用了 `@BeforeEach`，但有少量重复代码
- 合格：部分使用了 `@BeforeEach`
- 不合格：每个测试方法都重复创建实例和数据

**代码风格**：
- 优秀：符合 Java 命名规范，代码整洁，注释恰当
- 良好：基本符合规范
- 合格：有少量规范问题
- 不合格：命名混乱，代码难以阅读

**测试组织**：
- 优秀：按功能分组，相关测试在一起，使用合适的测试类命名
- 良好：测试组织合理
- 合格：组织尚可，但有改进空间
- 不合格：测试混乱，难以找到特定功能的测试

---

### 4. AI 协作能力（20%）

**审查深度**：
- 优秀：发现 AI 生成代码的关键缺陷（如测试通过但代码可能是错的）
- 良好：发现明显问题（如重复代码、缺失边界情况）
- 合格：发现表面问题
- 不合格：未发现实质问题，或未进行审查

**修复质量**：
- 优秀：修复后的代码质量高，考虑了更多边界情况
- 良好：修复了发现的问题
- 合格：部分修复
- 不合格：修复引入新问题

**反思总结**：
- 优秀：对 AI 的能力边界有深刻认识，能总结 AI 在测试生成中的常见缺陷
- 良好：有合理的反思
- 合格：有反思但不够深入
- 不合格：无反思或反思流于表面

---

## 总分计算

| 等级 | 分数范围 | 说明 |
|------|----------|------|
| A | 90-100 | 优秀，所有维度表现突出 |
| B | 80-89 | 良好，少数方面可改进 |
| C | 70-79 | 合格，达到基本要求 |
| D | 60-69 | 及格，有明显不足 |
| F | <60 | 不合格，需要重做 |

---

## 常见扣分项

1. **测试无法运行**（-20 分）
   - 编译错误
   - 依赖配置错误
   - 测试运行失败

2. **覆盖率不达标**（-10 分）
   - 基础作业覆盖率 < 80%
   - CampusFlow 覆盖率 < 80%

3. **AI 输出未审查直接提交**（-15 分）
   - 直接复制 AI 生成的测试代码
   - 无审查清单或审查流于形式

4. **测试命名不规范**（-5 分）
   - 使用 `test1`、`test2` 等无意义命名

5. **缺少异常测试**（-5 分）
   - 未使用 `assertThrows` 测试异常场景

6. **未使用参数化测试**（-5 分）
   - 未使用 `@ParameterizedTest`

---

## 加分项（最高 +10 分）

1. **覆盖率 95%+**（+5 分）
2. **AI 审查发现关键设计缺陷**（+3 分）
3. **编写了让 AI 测试通过的"错误实现"**（+2 分）

---

## 提交检查清单（学生自测）

在提交前，请确认：

- [ ] 运行 `mvn test` 所有测试通过
- [ ] `LibraryTracker` 所有 public 方法都有测试
- [ ] 使用了 `@BeforeEach` 消除重复代码
- [ ] 使用了 `assertThrows` 测试异常场景
- [ ] 使用了 `@ParameterizedTest` 至少 1 处
- [ ] 覆盖率 >= 80%（运行 `mvn test` 后查看 `target/site/jacoco/index.html`）
- [ ] CampusFlow Repository 测试完成
- [ ] AI 协作练习完成（如选择做）
- [ ] 提交了所有要求的截图和文档

---

## 教师评分备注

**快速评分流程**：
1. 克隆学生仓库
2. 运行 `mvn test`，确认所有测试通过
3. 检查 `target/site/jacoco/index.html` 确认覆盖率
4. 抽查 2-3 个测试方法的质量（断言、命名、边界情况）
5. 检查 AI 协作练习（如提交）

**参考命令**：
```bash
# 克隆并测试
git clone <student-repo-url>
cd <project-dir>
mvn test

# 查看覆盖率报告（生成后在浏览器打开）
mvn jacoco:report
# 打开 target/site/jacoco/index.html
```
